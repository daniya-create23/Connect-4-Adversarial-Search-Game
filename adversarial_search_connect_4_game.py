# -*- coding: utf-8 -*-
"""Adversarial_Search_Connect-4-Game

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19h4PpAqkIpoN3RT_w2N4JCNX41NkJ3JY
"""

import random
import math
import pandas as pd
import numpy as np

# Global counters for alpha-beta pruning
alpha_prunes = 0
beta_prunes = 0

# Constants to represent players
PLAYER_AGENT = 1  # Agent (Minimax or Expectimax)
PLAYER_OPPONENT = 2  # Opponent (Random or other Agent)

# Connect-4 board dimensions
ROWS = 6
COLS = 7


# Create an empty Connect-4 board
def create_empty_board():
    return [[0 for _ in range(COLS)] for _ in range(ROWS)]


# Check if a column is valid (i.e., not full)
def valid_columns(board):
    return [col for col in range(COLS) if board[0][col] == 0]


# Simulate dropping a disc into a column for a player
def simulate_move(board, col, player):
    new_board = [row[:] for row in board]  # Copy the board
    for row in range(ROWS - 1, -1, -1):
        if new_board[row][col] == 0:
            new_board[row][col] = player
            break
    return new_board


# Check for a win (connect 4)
def check_winner(board, player):
    # Check horizontal, vertical, and diagonal connections
    for row in range(ROWS):
        for col in range(COLS - 3):
            if all(board[row][col + i] == player for i in range(4)):
                return True

    for row in range(ROWS - 3):
        for col in range(COLS):
            if all(board[row + i][col] == player for i in range(4)):
                return True

    for row in range(ROWS - 3):
        for col in range(COLS - 3):
            if all(board[row + i][col + i] == player for i in range(4)):
                return True
            if all(board[row + 3 - i][col + i] == player for i in range(4)):
                return True

    return False


# Check if the board is full (draw condition)
def is_full_board(board):
    return all(board[0][col] != 0 for col in range(COLS))


# Check if the state is terminal (win or draw)
def is_terminal_state(board):
    return check_winner(board, PLAYER_AGENT) or check_winner(board, PLAYER_OPPONENT) or is_full_board(board)


# Improved evaluation function (example)
def evaluate_board(board):
    score = 0
    # Add heuristics for player advantage
    for row in range(ROWS):
        for col in range(COLS):
            if board[row][col] == PLAYER_AGENT:
                score += 1  # Example scoring for Agent
            elif board[row][col] == PLAYER_OPPONENT:
                score -= 1  # Penalize for opponent

    # Add randomness to score
    return score + random.randint(-2, 2)  # Random factor to add variability


# Minimax with alpha-beta pruning
def minimax(board, depth, alpha, beta, maximizing_player):
    global alpha_prunes, beta_prunes
    if depth == 0 or is_terminal_state(board):
        return evaluate_board(board)

    if maximizing_player:
        max_eval = -math.inf
        for col in valid_columns(board):
            new_board = simulate_move(board, col, PLAYER_AGENT)
            eval = minimax(new_board, depth - 1, alpha, beta, False)
            max_eval = max(max_eval, eval)
            alpha = max(alpha, eval)
            if beta <= alpha:
                alpha_prunes += 1  # Alpha pruning occurs
                break  # Alpha-beta pruning
        return max_eval
    else:
        min_eval = math.inf
        for col in valid_columns(board):
            new_board = simulate_move(board, col, PLAYER_OPPONENT)
            eval = minimax(new_board, depth - 1, alpha, beta, True)
            min_eval = min(min_eval, eval)
            beta = min(beta, eval)
            if beta <= alpha:
                beta_prunes += 1  # Beta pruning occurs
                break  # Alpha-beta pruning
        return min_eval


# Expectimax algorithm with enhanced probability influence for agent B
# Expectimax algorithm with enhanced probability influence for agent B
def expectimax_with_probability(board, depth, maximizing_player, p=0.5):
    if depth == 0 or is_terminal_state(board):
        return evaluate_board(board)

    if maximizing_player:
        max_eval = -math.inf
        for col in valid_columns(board):
            new_board = simulate_move(board, col, PLAYER_AGENT)
            eval = expectimax_with_probability(new_board, depth - 1, False, p)
            max_eval = max(max_eval, eval)
        return max_eval
    else:
        expected_value = 0
        valid_moves = valid_columns(board)

        # Evaluate all possible moves for PLAYER_OPPONENT
        evaluations = []
        for col in valid_moves:
            new_board = simulate_move(board, col, PLAYER_OPPONENT)
            eval = evaluate_board(new_board)
            evaluations.append((eval, col))

        # Sort moves from best to worst based on evaluation
        evaluations.sort(reverse=True)

        # Compute expected value with probability
        for i, (eval, col) in enumerate(evaluations):
            if i == 0:  # Best move
                weight = p  # Higher probability to choose the best move when p is higher
            else:
                # Spread remaining probability over suboptimal moves
                weight = (1 - p) / (len(valid_moves) - 1)

            new_board = simulate_move(board, col, PLAYER_OPPONENT)
            eval = expectimax_with_probability(new_board, depth - 1, True, p)

            # More randomness when p is low, more accuracy when p is high
            expected_value += eval * weight

        return expected_value


# Random move for Agent C
def get_random_move(board):
    valid_moves = valid_columns(board)
    if not valid_moves:
        return None  # No valid moves, game is likely over
    return random.choice(valid_moves)  # Select a random valid column


# Best move for Agent A (Minimax)
def get_best_move_minimax(board, depth):
    best_value = -math.inf
    best_move = None
    for col in valid_columns(board):
        new_board = simulate_move(board, col, PLAYER_AGENT)
        move_value = minimax(new_board, depth - 1, -math.inf, math.inf, False)
        if move_value > best_value:
            best_value = move_value
            best_move = col
    return best_move


def get_best_move_expectimax(board, depth, p):
    best_value = -math.inf
    best_move = None
    valid_moves = valid_columns(board)

    evaluations = []
    for col in valid_moves:
        new_board = simulate_move(board, col, PLAYER_AGENT)
        move_value = expectimax_with_probability(new_board, depth - 1, False, p)
        evaluations.append((move_value, col))

    # Sort moves based on evaluation, best moves first
    evaluations.sort(reverse=True, key=lambda x: x[0])

    # Weighted selection process based on probability p
    cumulative_weights = []
    for i in range(len(valid_moves)):
        if i == 0:  # Strong preference for best move
            cumulative_weights.append(p)
        else:
            cumulative_weights.append(cumulative_weights[-1] + (1 - p) / (len(valid_moves) - 1))

    # Randomly select based on cumulative weights
    r = random.random()
    for i, (eval, col) in enumerate(evaluations):
        if r <= cumulative_weights[i]:
            best_move = col
            break

    return best_move


def play_game(agent_a_type, agent_b_type, depth=4, p_b=1):
    board = create_empty_board()
    current_player = PLAYER_AGENT  # Start with Agent A
    global alpha_prunes, beta_prunes
    alpha_prunes = 0
    beta_prunes = 0
    turns = 0  # Initialize turns counter

    while True:
        if current_player == PLAYER_AGENT:
            if agent_a_type == "minimax":
                move = get_best_move_minimax(board, depth)
            elif agent_a_type == "expectimax":
                move = get_best_move_expectimax(board, depth, p_b)
            elif agent_a_type == "random":
                move = get_random_move(board)
        else:
            if agent_b_type == "minimax":
                move = get_best_move_minimax(board, depth)
            elif agent_b_type == "expectimax":
                move = get_best_move_expectimax(board, depth, p_b)
            elif agent_b_type == "random":
                move = get_random_move(board)

        # If no move is available, declare draw (no need to check winner)
        if move is None:
            return "Draw", alpha_prunes, beta_prunes, turns

        # Simulate the move on the board
        board = simulate_move(board, move, current_player)
        turns += 1  # Increment the turns counter

        # Check for a winner
        if check_winner(board, PLAYER_AGENT):
            return "Player 1", alpha_prunes, beta_prunes, turns
        elif check_winner(board, PLAYER_OPPONENT):
            return "Player 2", alpha_prunes, beta_prunes, turns

        # Switch players
        current_player = PLAYER_OPPONENT if current_player == PLAYER_AGENT else PLAYER_AGENT


# Run the specified matches with probabilities
def run_specified_matches():
    results = []
    games_data = {
        "wins": [],
        "losses": [],
        "draws": [],
        "game_lengths": [],
        "alpha_prunes": [],
        "beta_prunes": []
    }

    # Match configurations with different probabilities for AgentB
    matches = [
        ("minimax", "minimax", "AgentA vs AgentA", 1),
        ("minimax", "random", "AgentA vs AgentC", 1),
        ("minimax", "expectimax", "AgentA vs AgentB, p=0.5", 0.5),
        ("expectimax", "random", "AgentB, p=0.75 vs AgentC", 0.75),
        ("expectimax", "random", "AgentB, p=0.5 vs AgentC", 0.5),
        ("expectimax", "random", "AgentB, p=0.25 vs AgentC", 0.25)
    ]

    # Running matches
    for agent_a, agent_b, match_name, p_b in matches:
        print(f"Running match: {match_name}")
        wins = losses = draws = 0
        game_lengths = []
        alpha_prunes_list = []
        beta_prunes_list = []

        for _ in range(10):
            winner, alpha_prunes, beta_prunes, game_length = play_game(agent_a, agent_b, depth=4, p_b=p_b)
            game_lengths.append(game_length)  # Append the actual game length
            alpha_prunes_list.append(alpha_prunes)
            beta_prunes_list.append(beta_prunes)

            if winner == "Player 1":
                wins += 1
            elif winner == "Player 2":
                losses += 1
            else:
                draws += 1

        # Accumulate results
        games_data["wins"].append(wins)
        games_data["losses"].append(losses)
        games_data["draws"].append(draws)
        games_data["game_lengths"].append(game_lengths)
        games_data["alpha_prunes"].append(alpha_prunes_list)
        games_data["beta_prunes"].append(beta_prunes_list)

        # Store match results
        results.append((match_name, wins, losses, draws))

    # Convert to DataFrame for better formatting
    df_results = pd.DataFrame(results, columns=["Match", "Wins", "Losses", "Draws"])
    print("\nMatch Results:")
    print(df_results)

    # Show additional stats
    for i in range(len(games_data["wins"])):
        avg_game_length = np.mean(games_data["game_lengths"][i])
        avg_alpha_prunes = np.mean(games_data["alpha_prunes"][i])
        avg_beta_prunes = np.mean(games_data["beta_prunes"][i])

        print(f"\nStats for {matches[i][2]}:")
        print(f"Total games: {10}")
        print(f"Wins: {games_data['wins'][i]}, Losses: {games_data['losses'][i]}, Draws: {games_data['draws'][i]}")
        print(f"Game lengths (10 runs): {games_data['game_lengths'][i]}")
        print(f"Alpha prunes (10 runs): {games_data['alpha_prunes'][i]}")
        print(f"Beta prunes (10 runs): {games_data['beta_prunes'][i]}")
        print(f"Average game length: {avg_game_length:.2f}")
        print(f"Average alpha prunes: {avg_alpha_prunes:.2f}")
        print(f"Average beta prunes: {avg_beta_prunes:.2f}")


# Run the simulation
run_specified_matches()